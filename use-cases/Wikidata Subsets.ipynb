{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Subsets of Wikidata\n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook is used to create smaller subgraphs from a larger input Wikidata graph. Notebook users can provide a list of Wikidata classes (**QNodes**) to remove and preserve to create desired subsets of Wikidata. \n",
    "\n",
    "## Prerequisite input data\n",
    "\n",
    "**`wikidata_root_folder`** : This folder should contain all wikidata files \n",
    "\n",
    "**`useful_files_output_folder`** : This folder should contain all computed files using input from `wikidata_root_folder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Invocation\n",
    "Example batch command. The second argument is a notebook where the output will be stored. You can load it to see progress. It is recommended to run this papermill command when the input data is very large (GB scale), as this notebook will take some time to finish running.\n",
    "\n",
    "```\n",
    "papermill 'Wikidata Subsets.ipynb' 'Wikidata Subsets.out.ipynb' \\\n",
    "-p output_path /nas/home/mbmann/subset2 \\\n",
    "-p output_folder output \\\n",
    "-p temp_folder temp.output \\\n",
    "-p wiki_root_folder /nas/home/mbmann/KGTK-public-graphs2/wikidata-20201130/data/ \\\n",
    "-p useful_files_output_folder /nas/home/mbmann/useful_files_output/output/useful_files/ \\\n",
    "-p notebooks_folder /nas/home/mbmann/kgtk_subset/kgtk/examples/ \\\n",
    "-p useful_files_notebook 'Wikidata\\ Useful\\ Files.ipynb' \\\n",
    "-p languages en, \\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import papermill as pm\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Folder on local machine where to create the output and temporary folders\n",
    "output_path = \"/nas/home/mbmann/subset2\"\n",
    "\n",
    "# The names of the output and temporary folders\n",
    "output_folder = \"output\"\n",
    "temp_folder = \"temp.output\"\n",
    "\n",
    "# The location of input files\n",
    "wiki_root_folder = \"/nas/home/mbmann/kgtk/datasets/wikidataos-v4-mm-2\"\n",
    "# wiki_root_folder = \"/nas/home/mbmann/KGTK-public-graphs2/wikidata-20201130/data/\"\n",
    "\n",
    "# The location of useful_files output\n",
    "useful_files_output_folder = \"/nas/home/mbmann/useful_files_output/output/useful_files/\"\n",
    "\n",
    "claims_file = \"claims.tsv.gz\"\n",
    "label_file = \"labels.en.tsv.gz\"\n",
    "alias_file = \"aliases.en.tsv.gz\"\n",
    "description_file = \"descriptions.en.tsv.gz\"\n",
    "item_file = \"claims.wikibase-item.tsv.gz\"\n",
    "qual_file = \"qualifiers.tsv.gz\"\n",
    "property_datatypes_file = \"metadata.property.datatypes.tsv.gz\"\n",
    "metadata_file = \"metadata.types.tsv.gz\" \n",
    "isa_file = \"derived.isa.tsv.gz\" #Preprocessed\n",
    "p279star_file = \"derived.P279star.tsv.gz\" #Preprocessed\n",
    "\n",
    "# Useful files Jupyter notebook\n",
    "useful_files_notebook = \"Wikidata Useful Files.ipynb\"\n",
    "notebooks_folder = \"/nas/home/mbmann/kgtk_subset/kgtk/examples/\"\n",
    "\n",
    "# Location of the cache database for kypher\n",
    "cache_path = f'{output_path}/{output_folder}'\n",
    "\n",
    "#Additional parameters\n",
    "delete_database = \"no\"\n",
    "compute_pagerank = \"no\"\n",
    "languages = \"en,\"\n",
    "\n",
    "# Whether to delete cache database\n",
    "if delete_database and delete_database.lower().strip() == 'yes':\n",
    "    delete_database = True\n",
    "else:\n",
    "    delete_database = False\n",
    "\n",
    "#Whether to compute pagerank\n",
    "if compute_pagerank and compute_pagerank.lower().strip() == 'yes':\n",
    "    compute_pagerank = True\n",
    "else:\n",
    "    compute_pagerank = False\n",
    "\n",
    "if languages:\n",
    "    languages = languages.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm if the system has zcat installed, so zcat commands can be run below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_code = os.system(\"which zcat\")\n",
    "if exit_code == 0:\n",
    "    print(\"PASS: zcat is available and will be used.\")\n",
    "else:\n",
    "    raise Exception(\"FAIL: zcat is a requirement, please install zcat to run this notebook in full.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python and Environment variables\n",
    "if cache_path:\n",
    "    store = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "    os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "else:\n",
    "    store = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "    os.environ['STORE'] = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "\n",
    "out = \"{}/{}\".format(output_path, output_folder)\n",
    "temp = \"{}/{}\".format(output_path, temp_folder)\n",
    "\n",
    "claims = wiki_root_folder + claims_file\n",
    "labels = wiki_root_folder + label_file\n",
    "aliases = wiki_root_folder + alias_file\n",
    "descriptions = wiki_root_folder + description_file\n",
    "items = wiki_root_folder + item_file\n",
    "quals = wiki_root_folder + qual_file\n",
    "datatypes = wiki_root_folder + property_datatypes_file \n",
    "metadata = wiki_root_folder + metadata_file \n",
    "isa = useful_files_output_folder + isa_file #Preprocessed\n",
    "p279star = useful_files_output_folder + p279star_file #Preprocessed\n",
    "\n",
    "# shortcuts to commands\n",
    "kgtk_path = \"~/anaconda3/envs/kgtk-subset/bin/kgtk\"\n",
    "kgtk = f'time {kgtk_path} --debug'\n",
    "kypher = f\"{kgtk_path} query --debug --graph-cache \" + store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the pre-computed files are avaialble from **useful_files_output_folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(isa) and os.path.isfile(p279star):\n",
    "    print(\"PASS: Precomputed input files exist and will be used.\")\n",
    "else: \n",
    "    raise Exception(\"FAIL: Precomputed input files do not exist. Please create them first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the output directory and create the subfolders for the output files and the temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {out}\n",
    "!mkdir {temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the output and temp folders before we start\n",
    "\n",
    "**NOTE:** This command will delete the previous output from `temp` and `output` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {out}/*.tsv {out}/*.tsv.gz\n",
    "!rm -r {out}/parts {out}/temp.useful_files {out}/useful_files\n",
    "!rm {temp}/*.tsv {temp}/*.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preserve the pre-existing cache database, if desired with **delete_database**\n",
    "- **delete_database** = `yes` if we want to create a new database\n",
    "- **delete_database** =  `no` if we want to use pre-existing cache database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete_database:\n",
    "    !rm {store}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good practice to peek a the files to make sure the column headings are what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {claims} \\\n",
    "--match '()-[]->()' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of all the items  to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[REQUIRED] Add classes to remove, given a list of classes** <br>\n",
    "- **Example:** Let's remove the class (scholarly article, 'Q13442814')\n",
    "- **NOTE:** This will only remove items that have a `P31_P279star` relation with the class\n",
    "\n",
    "**[OPTIONAL] Add instances to remove, given a list of instances** <br>\n",
    "- **Example:** Let's remove instances (Fireball, 'Q5451712'), (Bush, 'Q1017471'), and (Italian Grape Ale, 'Q67772833')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_remove = ['Q34508', 'Q7378']\n",
    "# classes_to_remove = ['Q13442814', 'Q523', 'Q318', 'Q7318358', 'Q7187', 'Q11173', 'Q8054'] #Parameter: Add classes manually here\n",
    "instances_to_remove = []\n",
    "\n",
    "classes = ', '.join([f'\"{c}\"' for c in classes_to_remove])\n",
    "instances = ', '.join([f'\"{c}\"' for c in instances_to_remove])\n",
    "print('classes: ', classes)\n",
    "print('instances: ', instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the items to be removed via classes\n",
    "\n",
    "First look at the classes we will remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given all classes in `classes.remove2`, find all subclasses from `p279star`. <br>\n",
    "2. Given all subclasses from `p279star`, find all subclass instances from `isa`\n",
    "3. The resulting items to remove will be in `{temp}/items.remove.byclass.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classes != '' and instances == '':\n",
    "    print('Finding items to remove based on classes only.')\n",
    "    cmd = f'''\n",
    "    {kypher} -i {p279star} -i {isa} \\\n",
    "    --match 'isa: (item)-[:isa]->(subclass), P279star: (subclass)-[:P279star]->(c)' \\\n",
    "    --return 'distinct item, \"p31_p279star\" as label, c as node2' \\\n",
    "    --where 'c in [{classes}]' \\\n",
    "    -o {temp}/items.remove.byclass.tsv.gz\n",
    "    '''\n",
    "    !{cmd}\n",
    "else:\n",
    "    print('Finding items to remove based on classes and instances.')\n",
    "    cmd = f'''\n",
    "    {kypher} -i {p279star} -i {isa} \\\n",
    "    --match 'isa: (item)-[:isa]->(subclass), P279star: (subclass)-[:P279star]->(c)' \\\n",
    "    --return 'distinct item, \"p31_p279star\" as label, c as node2' \\\n",
    "    --where 'c in [{classes}] OR item in [{instances}]' \\\n",
    "    -o {temp}/items.remove.byclass.tsv.gz\n",
    "    '''\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat {temp}/items.remove.byclass.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the items to be removed via out degree\n",
    "\n",
    "Specify the # of node out-degrees `k`, and identify items with out-degree less than `k`\n",
    "- Ex: Find items that have out-degree `k` less than 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of items that have out_degree < `k`, along with any parent classses they belong to. <br>\n",
    "Put the results into `items.remove.bydegree.tsv.gz`. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 2 #Parameter\n",
    "# !{kypher} -i {useful_files_output_folder}metadata.out_degree.sorted.tsv.gz \\\n",
    "# --match 'out: (item)-[:out_degree]->(n2)' \\\n",
    "# --where \"cast(n2, integer) <= {k} and upper(substr(item,0)) >= 'Q'\" \\\n",
    "# --return 'distinct item, \"out_degree\" as label, n2 as node2' \\\n",
    "# -o {temp}/items.remove.bydegree.tsv.gz \\\n",
    "\n",
    "# !zcat {temp}/items.remove.bydegree.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the items to remove by-class and by-outdegree\n",
    "Concatenate all items from `items.remove.byclass` and `items.remove.bydegree`.\n",
    "The resulting list of items to remove will be `items.remove`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} cat -i {temp}/items.remove.*.tsv.gz \\\n",
    "-o {temp}/items.remove.tsv.gz\n",
    "!zcat {temp}/items.remove.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deduplicate the concatenated file of items to remove. <br>\n",
    "The resulting list of items to remove will be `items.remove2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/items.remove.tsv.gz -o {temp}/items.remove.sorted.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} compact -i {temp}/items.remove.sorted.tsv.gz -o {temp}/items.remove2.tsv.gz \\\n",
    "--columns 'node1'\n",
    "!zcat {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the items we will remove\n",
    "Check the `items.remove` file for classes added via different methods: 1) by-class, 2) by-instance, 3) by-outdegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check for class added manually, i.e. (scholarly article, 'Q13442814')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zgrep 'Q13442814' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check for class added by-instance, i.e. (Fireball, 'Q5451712')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zgrep 'Q5451712' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Check for class added by-outdegree, i.e. (??, 'Q100000030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zgrep 'Q100000030' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the classes of items we will remove, just as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {temp}/items.remove2.tsv.gz \\\n",
    "--match '(n1)-[]->()' \\\n",
    "--return 'count(distinct n1)' \\\n",
    "\n",
    "!{kypher} -i {temp}/items.remove2.tsv.gz \\\n",
    "--match '(n1)-[]->()' \\\n",
    "--return 'distinct n1' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TODO] Create a list of all items to protect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced edges file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the items from the all.tsv and the label, alias and description files\n",
    "We will be left with `reduced` files where the edges do not have the unwanted items. We have to remove them from the node1 and node2 positions, so we need to run the ifnotexists commands twice.\n",
    "\n",
    "Before we start preview the files to see the column headings and check whether they look sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/items.remove2.tsv.gz -o {temp}/items.remove2.sorted.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {temp}/items.remove2.sorted.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove from the full set of edges those edges that have a `node1` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} ifnotexists -i {claims} -o {temp}/item.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the remaining edges, remove those that have a `node2` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/item.edges.reduced.tsv.gz -o {temp}/item.edges.reduced.sorted.tsv.gz \\\n",
    "--columns node2 label node1 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} ifnotexists -i {temp}/item.edges.reduced.sorted.tsv.gz -o {temp}/item.edges.reduced.2.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node2 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} ifnotexists -i {labels} -o {temp}/label.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/label.edges.reduced.tsv.gz -o {out}/labels.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} ifnotexists -i {aliases} -o {temp}/alias.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} ifnotexists -i {descriptions} -o {temp}/description.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the output files for claims, labels, aliases and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/item.edges.reduced.2.tsv.gz -o {out}/claims.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/label.edges.reduced.tsv.gz -o {out}/labels.en.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/alias.edges.reduced.tsv.gz -o {out}/aliases.en.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {temp}/description.edges.reduced.tsv.gz -o {out}/descriptions.en.tsv.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests: Confirm items were removed from claims file\n",
    "**NOTE:** We will check the items we removed do not exist in claims file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Confirm no instance of class added manually, i.e. (scholarly article, 'Q13442814')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST: This should not return anything, as it has been removed from claims.tsv.gz\n",
    "# !zgrep 'Q13442814' {out}/claims.tsv.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Confirm no instance of instance added manually, i.e. (Fireball, 'Q5451712')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zgrep 'Q5451712\t' {out}/claims.tsv.gz #PASS: No result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Confirm no instance with out-degree < 2, i.e. (instance: 'Q100000030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !zgrep 'Q100000030\t' {out}/claims.tsv.gz #PASS: No result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced qualifiers file\n",
    "We do this by finding all the ids of the reduced edges file, and then selecting out from `qual.tsv`\n",
    "\n",
    "We need to join by id, so we need to sort both files by id, node1, label, node2:\n",
    "\n",
    "- `{quals}` \n",
    "- `{out}/claims.tsv.gz` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {quals} | head | column -t -s $'\\t' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `ifexists` to select out the quals for the edges in `{out}/wikidataos.qual.tsv.gz`. Note that we use `node1` in the qualifier file, matching to `id` in the `wikidataos.all.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$kgtk ifexists -i {quals} -o {out}/qualifiers.tsv.gz \\\n",
    "--filter-on {out}/claims.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys id \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the final output for qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {out}/qualifiers.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call partition and useful_files notebooks, to generate the file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgtk_scripts_path = \"/nas/home/mbmann/kgtk_subset/kgtk\"\n",
    "os.environ[\"EXAMPLES_DIR\"] = kgtk_scripts_path + \"/examples\"\n",
    "os.environ[\"USECASE_DIR\"] = kgtk_scripts_path + \"/use-cases\"\n",
    "os.environ[\"TEMP\"] = temp\n",
    "os.environ[\"OUT\"] = out\n",
    "os.environ[\"DATATYPES\"] = datatypes\n",
    "os.environ[\"METADATA\"] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"EXAMPLES_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"$TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"$OUT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate all output files together** <br>\n",
    "\n",
    "**NOTE:** The `metadata.property.datatypes` and `metadata.types` are not currently generated by this notebook, and have been copied from `wikidata-20200803-v5/data`. <br>\n",
    "**TODO:** We must confirm if these are source files, or computed. If they are computed, we should compute them in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} cat \\\n",
    "-i {out}/aliases.en.tsv.gz \\\n",
    "-i {out}/descriptions.en.tsv.gz \\\n",
    "-i {out}/qualifiers.tsv.gz \\\n",
    "-i {out}/claims.tsv.gz \\\n",
    "-i {out}/labels.en.tsv.gz \\\n",
    "-i {datatypes} \\\n",
    "-i {metadata} \\\n",
    "-o {out}/all.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {os.environ[\"EXAMPLES_DIR\"] + \"/partition-wikidata.ipynb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the partition-wikidata notebook\n",
    "`partition-wikidata` will take all intermediary computed outputs from `all.tsv.gz` and partition each wikidata entity (i.e. claims, aliases, labels, descriptions, qualifiers), into partitions. <br>\n",
    "\n",
    "**NOTE:** This notebook also produces `claims.wikibase-item.tsv.gz` and outputs it to `wikidata_parts_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.execute_notebook(\n",
    "    os.environ[\"EXAMPLES_DIR\"] + \"/partition-wikidata.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/partition-wikidata.out.ipynb\",\n",
    "    parameters=dict(\n",
    "        wikidata_input_path = os.environ[\"OUT\"] + \"/all.tsv.gz\",\n",
    "        wikidata_parts_path = os.environ[\"OUT\"] + \"/parts\",\n",
    "        temp_folder_path = os.environ[\"OUT\"] + \"/parts/temp\",\n",
    "        sort_extras = \"--buffer-size 30% --temporary-directory $OUT/parts/temp\",\n",
    "        verbose = False\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the useful-files notebook\n",
    "`Wikidata Useful Files` will take intermediary output generated by `partition-wikidata` and produce the following statistics: `derived.P31.tsv.gz`, `derived.P279.tsv.gz`, `derived.isa.tsv.gz`, `derived.P279star.tsv.gz`, and `metadata.out_degree.tsv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Don't pass in cache path, as one doesn't yet exist for useful_files\n",
    "pm.execute_notebook(\n",
    "    os.environ[\"USECASE_DIR\"] + \"/Wikidata Useful Files.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/Wikidata Useful Files Out.ipynb\",\n",
    "    parameters=dict(\n",
    "        output_path = os.environ[\"OUT\"],\n",
    "        output_folder = \"useful_files\",\n",
    "        temp_folder = \"temp.useful_files\",\n",
    "        wiki_root_folder = os.environ[\"OUT\"] + \"/parts/\",\n",
    "        languages = 'en',\n",
    "        compute_pagerank = True,\n",
    "        delete_database = False\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {out}/*wikidataos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {out}/wikidataos.all.tsv.gz | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges file must contain edges for properties, this is not the case on 2020-11-10`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz \\\n",
    "--match '(:P10)-[l]->(n2)' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} cat -i {out}/claims.tsv.gz \\\n",
    "{out}/qualifiers.tsv.gz \\\n",
    "{out}/useful_files/metadata.pagerank.undirected.tsv.gz \\\n",
    "{out}/useful_files/metadata.pagerank.directed.tsv.gz \\\n",
    "{out}/useful_files/metadata.in_degree.sorted.tsv.gz \\\n",
    "{out}/useful_files/metadata.out_degree.sorted.tsv.gz \\\n",
    "-o {out}/wikidataos.all.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all for triples` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} cat -i {out}/wikidataos.all.tsv.gz \\\n",
    "{out}/useful_files/derived.P31.tsv.gz \\\n",
    "{out}/useful_files/derived.P279.tsv.gz \\\n",
    "{out}/useful_files/derived.isa.tsv.gz \\\n",
    "{out}/useful_files/derived.P279star.tsv.gz \\\n",
    "-o {out}/wikidataos.all.for.triples.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out `novalue`, `somevalue` and `P9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} filter -i {out}/wikidataos.all.for.triples.tsv.gz \\\n",
    "-o {out}/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "-p ';;somevalue,novalue,P9' --invert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ids for any edge with missing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} add-id -i {out}/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "-o {out}/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "--id-style wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} sort2 -i {out}/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "-o {out}/wikidataos.all.for.triples.filtered.id.sorted.tsv.gz \\\n",
    "-c id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "kgtk-subset",
   "language": "python",
   "name": "kgtk-subset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
