{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Subsets of Wikidata\n",
    "\n",
    ">Warning: \n",
    "**This notebook is under construction and it doesn't work**\n",
    "\n",
    "## Purpose\n",
    "\n",
    ">This notebook is used to create smaller subgraphs from a larger input Wikidata graph. Notebook users can provide a list of Wikidata classes (**QNodes**) to remove and preserve to create desired subsets of Wikidata. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Invocation\n",
    "Example batch command. The second argument is a notebook where the output will be stored. You can load it to see progress.\n",
    "\n",
    "UPDATE EXAMPLE INVOCATION\n",
    "\n",
    "\n",
    "```\n",
    "papermill Wikidata\\ Useful\\ Files.ipynb useful-files.out.ipynb \\\n",
    "-p wiki_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/all.tsv.gz \\\n",
    "-p label_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.label.en.tsv.gz \\\n",
    "-p item_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.wikibase-item.tsv.gz \\\n",
    "-p property_item_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/part.property.wikibase-item.tsv.gz \\\n",
    "-p qual_file /Volumes/GoogleDrive/Shared\\ drives/KGTK-public-graphs/wikidata-20200803-v3/qual.tsv.gz \\\n",
    "-p output_path <local folder> \\\n",
    "-p output_folder useful_files_v4 \\\n",
    "-p temp_folder temp.useful_files_v4 \\\n",
    "-p delete_database no \\\n",
    "-p compute_pagerank no \\\n",
    "-p languages es,ru,zh-cn \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import papermill as pm\n",
    "\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Folder on local machine where to create the output and temporary folders\n",
    "# output_path = \"/Users/pedroszekely/Downloads/kypher\"\n",
    "# output_path = \"/Users/markmann/Downloads/subset\"\n",
    "output_path = \"/nas/home/mbmann/subset\"\n",
    "\n",
    "# The names of the output and temporary folders\n",
    "output_folder = \"output\"\n",
    "temp_folder = \"temp.output\"\n",
    "\n",
    "# Classes to remove\n",
    "#Q34508 - video tape recording\n",
    "# remove_classes = \"Q13442814, Q523, Q16521, Q318, Q7318358, Q7187, Q11173, Q8054, Q5, Q13100073, Q8502, Q3305213, Q4022, Q79007, Q1931185, Q30612, Q101352, Q54050, Q13433827, Q2668072, Q23397, Q3863, Q11424, Q482994, Q47150325, Q16970, Q18593264, Q355304, Q9842, Q7725634, Q27020041, Q56436498, Q2154519, Q61443690, Q49008, Q3331189, Q47521, Q5084, Q19389637, Q21014462, Q4164871, Q11060274, Q5633421, Q39816, Q5185279, Q55488, Q134556, Q22698, Q985488, Q1260524, Q204107, Q2225692, Q215380, Q71963409, Q452237, Q93184, Q12323\"\n",
    "# remove_classes = \"Q34508\"\n",
    "\n",
    "# The location of input files\n",
    "# wiki_root_folder = \"/Volumes/GoogleDrive/Shared\\ drives/KGTK/datasets/wikidata-20200803-v4/\"\n",
    "# wiki_root_folder = \"/Volumes/GoogleDrive/Shared\\ drives/KGTK/datasets/wikidata-20200803-v4/\"\n",
    "# wiki_root_folder = \"/Users/pedroszekely/Downloads/kypher/wikidataos-v4/\"\n",
    "# wiki_root_folder = \"/Users/markmann/Google\\ Drive/Shared\\ drives/KGTK/datasets/wikidataos-v4-mm-2/\"\n",
    "wiki_root_folder = \"/nas/home/mbmann/kgtk/datasets/wikidataos-v4-mm-2/\"\n",
    "\n",
    "metadata_folder = \"/nas/home/mbmann/kgtk/datasets/wikidata-20200803-v5/data/\"\n",
    "\n",
    "claims_file = \"claims.tsv.gz\"\n",
    "label_file = \"labels.en.tsv.gz\"\n",
    "alias_file = \"aliases.en.tsv.gz\"\n",
    "description_file = \"descriptions.en.tsv.gz\"\n",
    "item_file = \"claims.wikibase-item.tsv.gz\"\n",
    "qual_file = \"qualifiers.tsv.gz\"\n",
    "property_datatypes_file = \"metadata.property.datatypes.tsv.gz\" #FIX\n",
    "metadata_file = \"metadata.types.tsv.gz\" #FIX\n",
    "isa_file = \"derived.isa.tsv.gz\"\n",
    "p279star_file = \"derived.P279star.tsv.gz\"\n",
    "\n",
    "# Useful files Jupyter notebook\n",
    "useful_files_notebook = \"Wikidata Useful Files.ipynb\"\n",
    "# notebooks_folder = \"/Users/markmann/Desktop/CKG/kgtk_subset/kgtk/examples/\"\n",
    "notebooks_folder = \"/nas/home/mbmann/kgtk_subset/kgtk/examples/\"\n",
    "\n",
    "# Location of the cache database for kypher\n",
    "# cache_path = \"/Users/pedroszekely/Downloads/kypher/wikidataos-v4\"\n",
    "cache_path = f'{output_path}/{output_folder}'\n",
    "\n",
    "#Additional parameters\n",
    "delete_database = \"no\"\n",
    "compute_pagerank = \"no\"\n",
    "languages = \"\"\n",
    "\n",
    "### Needs fixing\n",
    "# Whether to delete the cache database\n",
    "if delete_database and delete_database.lower().strip() == 'yes':\n",
    "    delete_database = True\n",
    "else:\n",
    "    delete_database = False\n",
    "\n",
    "### Needs fixing\n",
    "if compute_pagerank and compute_pagerank.lower().strip() == 'yes':\n",
    "    compute_pagerank = True\n",
    "else:\n",
    "    compute_pagerank = False\n",
    "\n",
    "if languages:\n",
    "    languages = languages.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment variables\n",
    "if cache_path:\n",
    "    os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "else:\n",
    "    os.environ['STORE'] = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "\n",
    "#Python variables\n",
    "if cache_path:\n",
    "    store = \"{}/wikidata.sqlite3.db\".format(cache_path)\n",
    "else:\n",
    "    store = \"{}/{}/wikidata.sqlite3.db\".format(output_path, temp_folder)\n",
    "\n",
    "out = \"{}/{}\".format(output_path, output_folder)\n",
    "temp = \"{}/{}\".format(output_path, temp_folder)\n",
    "\n",
    "claims = wiki_root_folder + claims_file\n",
    "labels = wiki_root_folder + label_file\n",
    "aliases = wiki_root_folder + alias_file\n",
    "descriptions = wiki_root_folder + description_file\n",
    "items = wiki_root_folder + item_file\n",
    "quals = wiki_root_folder + qual_file\n",
    "isa = wiki_root_folder + isa_file\n",
    "p279star = wiki_root_folder + p279star_file\n",
    "\n",
    "datatypes = metadata_folder + property_datatypes_file #FIX\n",
    "metadata = metadata_folder + metadata_file #FIX\n",
    "\n",
    "# shortcuts to commands\n",
    "kgtk_path = \"~/anaconda3/envs/kgtk-subset/bin/kgtk\"\n",
    "kgtk = f'time {kgtk_path} --debug'\n",
    "kypher = f\"{kgtk_path} query --debug --graph-cache \" + store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the output directory and create the subfolders for the output files and the temporary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/nas/home/mbmann/subset/output’: File exists\n",
      "mkdir: cannot create directory ‘/nas/home/mbmann/subset/temp.output’: File exists\n"
     ]
    }
   ],
   "source": [
    "!cd $output_path\n",
    "!mkdir {out}\n",
    "!mkdir {temp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the output and temp folders before we start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm {out}/*.tsv {out}/*.tsv.gz\n",
    "# !rm {temp}/*.tsv {temp}/*.tsv.gz\n",
    "\n",
    "if delete_database:\n",
    "    !rm {out}/*.tsv {out}/*.tsv.gz\n",
    "    !rm {temp}/*.tsv {temp}/*.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always a good practice to peek a the files to make sure the column headings are what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:58:00 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     LIMIT ?\n",
      "  PARAS: [10]\n",
      "---------------------------------------------\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "P10-P1628-32b85d-7927ece6-0\tP10\tP1628\t\"http://www.w3.org/2006/vcard/ns#Video\"\tnormal\turl\n",
      "P10-P1628-acf60d-b8950832-0\tP10\tP1628\t\"https://schema.org/video\"\tnormal\turl\n",
      "P10-P1629-Q34508-bcc39400-0\tP10\tP1629\tQ34508\tnormal\twikibase-item\n",
      "P10-P1659-P1651-c4068028-0\tP10\tP1659\tP1651\tnormal\twikibase-property\n",
      "P10-P1659-P18-5e4b9c4f-0\tP10\tP1659\tP18\tnormal\twikibase-property\n",
      "P10-P1659-P4238-d21d1ac0-0\tP10\tP1659\tP4238\tnormal\twikibase-property\n",
      "P10-P1659-P51-86aca4c5-0\tP10\tP1659\tP51\tnormal\twikibase-property\n",
      "P10-P1855-Q7378-555592a4-0\tP10\tP1855\tQ7378\tnormal\twikibase-item\n",
      "P10-P31-Q18610173-85ef4d24-0\tP10\tP31\tQ18610173\tnormal\twikibase-item\n",
      "P1000-P1629-Q1241356-d5c10f50-0\tP1000\tP1629\tQ1241356\tnormal\twikibase-item\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {claims} \\\n",
    "--match '()-[]->()' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a list of all the items  to remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add classes to remove, based on <u>classes themselves</u> here:** <br>\n",
    "- **Example:** Let's remove the class (videotape recording, 'Q34508')\n",
    "- **NOTE:** This will only remove items that have a P31/P279 relation with the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:58:02 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT graph_1_c1.\"node2\", graph_1_c1.\"node1\", ? \"_aLias.label\"\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     WHERE graph_1_c1.\"label\"=?\n",
      "     AND (graph_1_c1.\"node2\" IN (?))\n",
      "  PARAS: ['p279', 'P279', 'Q34508']\n",
      "---------------------------------------------\n",
      "node2\tnode1\tlabel\n",
      "Q34508\tQ1926658\tp279\n",
      "Q34508\tQ20892182\tp279\n",
      "Q34508\tQ23058567\tp279\n",
      "Q34508\tQ25324511\tp279\n",
      "Q34508\tQ2916762\tp279\n",
      "Q34508\tQ48774253\tp279\n",
      "Q34508\tQ97065731\tp279\n",
      "Q34508\tQ97073931\tp279\n",
      "Q34508\tQ97078183\tp279\n"
     ]
    }
   ],
   "source": [
    "classes_to_remove = ['Q34508'] #Parameter: Add classes manually here\n",
    "classes = ', '.join([f'\"{c}\"' for c in classes_to_remove])\n",
    "\n",
    "!{kypher} -i {claims} -o {temp}/classes.remove.manual.tsv.gz \\\n",
    "--match '(instance)-[:P279]->(c)' \\\n",
    "--where 'c in [{classes}]' \\\n",
    "--return 'c, instance, \"p279\" as label'\n",
    "\n",
    "!zcat {temp}/classes.remove.manual.tsv.gz |head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add classes to remove, based on <u>instances</u> here:**\n",
    "- **Example:** Let's remove classes that are part of instance (Fireball, 'Q5451712'), (Bush, 'Q1017471'), and (Italin Grape Alle, 'Q67772833')\n",
    "- **NOTE:** The expected class to remove is (whisky, 'Q281'), (beer, 'Q44'), (beer brand, Q15075508), and (ale, 'Q208385')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the intances to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_to_remove = ['Q5451712', 'Q1017471', 'Q67772833'] #Parameter: Add instances manually here\n",
    "instances = ', '.join([f'\"{instance}\"' for instance in instances_to_remove])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all instances, get their **(P279, subclass)** from `claims.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:58:34 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     WHERE graph_1_c1.\"label\"=?\n",
      "     AND (graph_1_c1.\"node1\" IN (?, ?, ?))\n",
      "  PARAS: ['P279', 'Q5451712', 'Q1017471', 'Q67772833']\n",
      "---------------------------------------------\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "Q67772833-P279-Q208385-3af88d61-0\tQ67772833\tP279\tQ208385\tnormal\twikibase-item\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {claims} -o {temp}/classes.remove.p279.tsv.gz \\\n",
    "--match '(instance)-[:P279]->(c)' \\\n",
    "--where 'instance in [{instances}]' \\\n",
    "\n",
    "!zcat {temp}/classes.remove.p279.tsv.gz |head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all instances, get their **(P31, class)** from `claims.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:58:40 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT *\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     WHERE graph_1_c1.\"label\"=?\n",
      "     AND (graph_1_c1.\"node1\" IN (?, ?, ?))\n",
      "  PARAS: ['P31', 'Q5451712', 'Q1017471', 'Q67772833']\n",
      "---------------------------------------------\n",
      "id\tnode1\tlabel\tnode2\trank\tnode2;wikidatatype\n",
      "Q1017471-P31-Q15075508-61e783df-0\tQ1017471\tP31\tQ15075508\tnormal\twikibase-item\n",
      "Q1017471-P31-Q44-7580116c-0\tQ1017471\tP31\tQ44\tnormal\twikibase-item\n",
      "Q5451712-P31-Q281-2d4512be-0\tQ5451712\tP31\tQ281\tnormal\twikibase-item\n",
      "Q67772833-P31-Q44-2d9b5c1b-0\tQ67772833\tP31\tQ44\tnormal\twikibase-item\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {claims} -o {temp}/classes.remove.p31.tsv.gz \\\n",
    "--match '(instance)-[:P31]->(c)' \\\n",
    "--where 'instance in [{instances}]' \\\n",
    "\n",
    "!zcat {temp}/classes.remove.p31.tsv.gz |head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all `classes.remove.manual`, `classes.remove.p31`, and `classes.remove.p279` into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m0.665s\r\n",
      "user\t0m0.304s\r\n",
      "sys\t0m0.050s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} cat -i {temp}/classes.remove.manual.tsv.gz -i {temp}/classes.remove.p31.tsv.gz -i {temp}/classes.remove.p279.tsv.gz \\\n",
    "-o {temp}/classes.remove.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and remove duplicate classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.833s\n",
      "user\t0m0.389s\n",
      "sys\t0m0.083s\n",
      "node1\tlabel\tnode2\n",
      "Q15075508\tcount\t1\n",
      "Q208385\tcount\t1\n",
      "Q281\tcount\t1\n",
      "Q34508\tcount\t9\n",
      "Q44\tcount\t2\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} unique -i {temp}/classes.remove.tsv.gz \\\n",
    "-o {temp}/classes.remove2.tsv.gz\n",
    "\n",
    "!zcat {temp}/classes.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISSUE: Can't query for multiple relations for given node1 within same query\n",
    "#GITHUB: https://github.com/usc-isi-i2/kgtk/issues/330\n",
    "#Test 1\n",
    "# !{kypher} -i {claims} \\\n",
    "# --match '(n1)-[:P31]->(n2)' \\\n",
    "# --where 'n1 = \"Q5451712\"' \\\n",
    "\n",
    "#Test 2, Test 3 \n",
    "# !{kypher} -i {claims} \\\n",
    "# --match 'claims: (n1)-[l1 {label: p}]->(n2)' \\\n",
    "# --where 'n1 = \"Q5451712\" and p = \"P31\"' \\\n",
    "# --where 'n1 = \"Q5451712\" and p = \"P31\" OR p = \"P279\"' \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the items to be removed via classes\n",
    "\n",
    "First look at the classes we will remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\r\n",
      "Q15075508\tcount\t1\r\n",
      "Q208385\tcount\t1\r\n",
      "Q281\tcount\t1\r\n",
      "Q34508\tcount\t9\r\n",
      "Q44\tcount\t2\r\n"
     ]
    }
   ],
   "source": [
    "!zcat {temp}/classes.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given all classes in `classes.remove2`, find all subclasses from `p279star`. <br>\n",
    "2. Given all subclasses from `p279star`, find all subclass instances from `isa`\n",
    "3. The resulting items to remove will be in `{temp}/items.remove.byclass.tsv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:58:50 sqlstore]: DROP graph data table graph_7 from /nas/home/mbmann/subset/temp.output/classes.remove2.tsv.gz\n",
      "[2021-02-11 13:58:50 sqlstore]: IMPORT graph directly into table graph_11 from /nas/home/mbmann/subset/temp.output/classes.remove2.tsv.gz ...\n",
      "[2021-02-11 13:58:50 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_4_c1.\"node1\", ? \"_aLias.label\", graph_3_c2.\"node2\" \"_aLias.node2\"\n",
      "     FROM graph_11 AS graph_11_c3, graph_3 AS graph_3_c2, graph_4 AS graph_4_c1\n",
      "     WHERE graph_11_c3.\"label\"=?\n",
      "     AND graph_3_c2.\"label\"=?\n",
      "     AND graph_4_c1.\"label\"=?\n",
      "     AND graph_11_c3.\"node1\"=graph_3_c2.\"node2\"\n",
      "     AND graph_3_c2.\"node1\"=graph_4_c1.\"node2\"\n",
      "  PARAS: ['p31_p279star', 'count', 'P279star', 'isa']\n",
      "---------------------------------------------\n",
      "[2021-02-11 13:58:50 sqlstore]: CREATE INDEX on table graph_11 column label ...\n",
      "[2021-02-11 13:58:50 sqlstore]: ANALYZE INDEX on table graph_11 column label ...\n",
      "[2021-02-11 13:58:51 sqlstore]: CREATE INDEX on table graph_11 column node1 ...\n",
      "[2021-02-11 13:58:51 sqlstore]: ANALYZE INDEX on table graph_11 column node1 ...\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {temp}/classes.remove2.tsv.gz -i {p279star} -i {isa} \\\n",
    "--match 'isa: (item)-[:isa]->(subclass), P279star: (subclass)-[:P279star]->(c), class: (c)-[:count]->()' \\\n",
    "--return 'distinct item, \"p31_p279star\" as label, c as node2' \\\n",
    "-o {temp}/items.remove.byclass.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnnie Walker\n",
      "Q502268\tp31_p279star\tQ281\n",
      "Fireball\n",
      "Q5451712\tp31_p279star\tQ281\n"
     ]
    }
   ],
   "source": [
    "# !zcat {temp}/items.remove.byclass.tsv.gz | head\n",
    "!echo 'Johnnie Walker'\n",
    "!zgrep 'Q502268\t' {temp}/items.remove.byclass.tsv.gz\n",
    "!echo 'Fireball'\n",
    "!zgrep 'Q5451712\t' {temp}/items.remove.byclass.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the items to be removed via out degree\n",
    "\n",
    "Specify the # of node out-degrees `k`, and identify items with out-degree less than `k`\n",
    "- Ex: Find items that have out-degree `k` less than 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute out-degree for all QNodes in the `claims` file. Check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 13:59:30 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_1_c1.\"node1\" \"_aLias.node1\", count(DISTINCT graph_1_c1.\"id\") \"_aLias.node2\", ? \"_aLias.label\"\n",
      "     FROM graph_1 AS graph_1_c1\n",
      "     WHERE (upper(substr(graph_1_c1.\"node1\", ?)) >= ?)\n",
      "     GROUP BY \"_aLias.node1\"\n",
      "  PARAS: ['out_degree', 0, 'Q']\n",
      "---------------------------------------------\n",
      "node1\tnode2\tlabel\n",
      "Q1\t81\tout_degree\n",
      "Q1000\t559\tout_degree\n",
      "Q100000003\t11\tout_degree\n",
      "Q100000011\t9\tout_degree\n",
      "Q100000014\t9\tout_degree\n",
      "Q100000021\t9\tout_degree\n",
      "Q100000029\t10\tout_degree\n",
      "Q100000030\t2\tout_degree\n",
      "Q100000033\t10\tout_degree\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {claims} -o {temp}/metadata.out_degree.tsv.gz \\\n",
    "--match '(n1)-[l]->()' \\\n",
    "--where \"upper(substr(n1,0)) >= 'Q'\" \\\n",
    "--return 'distinct n1 as node1, count(distinct l) as node2, \"out_degree\" as label' \n",
    "\n",
    "!zcat {temp}/metadata.out_degree.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of items that have out_degree < `k`, along with any parent classses they belong to. <br>\n",
    "Put the results into `items.remove.bydegree.tsv.gz`. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 14:00:14 sqlstore]: DROP graph data table graph_8 from /nas/home/mbmann/subset/temp.output/metadata.out_degree.tsv.gz\n",
      "[2021-02-11 14:00:19 sqlstore]: IMPORT graph directly into table graph_12 from /nas/home/mbmann/subset/temp.output/metadata.out_degree.tsv.gz ...\n",
      "[2021-02-11 14:00:23 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_4_c2.\"node1\", ? \"_aLias.label\", graph_3_c3.\"node2\" \"_aLias.node2\"\n",
      "     FROM graph_12 AS graph_12_c1, graph_3 AS graph_3_c3, graph_4 AS graph_4_c2\n",
      "     WHERE graph_12_c1.\"label\"=?\n",
      "     AND graph_3_c3.\"label\"=?\n",
      "     AND graph_4_c2.\"label\"=?\n",
      "     AND graph_12_c1.\"node1\"=graph_4_c2.\"node1\"\n",
      "     AND graph_3_c3.\"node1\"=graph_4_c2.\"node2\"\n",
      "     AND (CAST(graph_12_c1.\"node2\" AS integer) <= ?)\n",
      "  PARAS: ['p31_p279star', 'out_degree', 'P279star', 'isa', 2]\n",
      "---------------------------------------------\n",
      "[2021-02-11 14:00:23 sqlstore]: CREATE INDEX on table graph_12 column node1 ...\n",
      "[2021-02-11 14:00:40 sqlstore]: ANALYZE INDEX on table graph_12 column node1 ...\n",
      "[2021-02-11 14:00:41 sqlstore]: CREATE INDEX on table graph_12 column label ...\n",
      "[2021-02-11 14:00:43 sqlstore]: ANALYZE INDEX on table graph_12 column label ...\n",
      "node1\tlabel\tnode2\n",
      "Q100000030\tp31_p279star\tQ1357761\n",
      "Q100000030\tp31_p279star\tQ14745\n",
      "Q100000030\tp31_p279star\tQ14748\n",
      "Q100000030\tp31_p279star\tQ15401930\n",
      "Q100000030\tp31_p279star\tQ15621286\n",
      "Q100000030\tp31_p279star\tQ16686448\n",
      "Q100000030\tp31_p279star\tQ17537576\n",
      "Q100000030\tp31_p279star\tQ223557\n",
      "Q100000030\tp31_p279star\tQ2424752\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "k = 2 #Parameter\n",
    "!{kypher} -i {temp}/metadata.out_degree.tsv.gz -i {isa} -i {p279star} \\\n",
    "--match 'out: (item)-[:out_degree]->(n2), isa: (item)-[:isa]->(subclass), P279star: (subclass)-[:P279star]->(c)' \\\n",
    "--where 'cast(n2, integer) <= {k}' \\\n",
    "--return 'distinct item, \"p31_p279star\" as label, c as node2' \\\n",
    "-o {temp}/items.remove.bydegree.tsv.gz \\\n",
    "\n",
    "!zcat {temp}/items.remove.bydegree.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the items to remove by-class and by-outdegree\n",
    "Concatenate all items from `items.remove.byclass` and `items.remove.bydegree`.\n",
    "The resulting list of items to remove will be `items.remove`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t2m17.588s\r\n",
      "user\t2m16.648s\r\n",
      "sys\t0m0.142s\r\n"
     ]
    }
   ],
   "source": [
    "# !zcat {temp}/items.remove.byclass.tsv.gz | head\n",
    "# !echo 'Johnnie Walker'\n",
    "# !zgrep 'Q502268\t' {temp}/items.remove.byclass.tsv.gz\n",
    "# !echo 'Fireball'\n",
    "# !zgrep 'Q5451712\t' {temp}/items.remove.byclass.tsv.gz\n",
    "\n",
    "# !zcat {temp}/items.remove.bydegree.tsv.gz | head\n",
    "# !zcat {temp}/items.remove.tsv.gz | head\n",
    "\n",
    "!{kgtk} cat -i {temp}/items.remove.byclass.tsv.gz {temp}/items.remove.bydegree.tsv.gz \\\n",
    "-o {temp}/items.remove.tsv.gz\n",
    "\n",
    "#Check if fireball is still in there\n",
    "# !echo 'Fireball'\n",
    "# !zgrep 'Q5451712\t' {temp}/items.remove.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deduplicate the concatenated file of items to remove. <br>\n",
    "The resulting list of items to remove will be `items.remove2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 14:08:45 sqlstore]: DROP graph data table graph_9 from /nas/home/mbmann/subset/temp.output/items.remove.tsv.gz\n",
      "[2021-02-11 14:08:54 sqlstore]: IMPORT graph directly into table graph_9 from /nas/home/mbmann/subset/temp.output/items.remove.tsv.gz ...\n",
      "[2021-02-11 14:09:07 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_9_c1.\"node1\", ? \"_aLias.label\", graph_9_c1.\"node2\" \"_aLias.node2\"\n",
      "     FROM graph_9 AS graph_9_c1\n",
      "     WHERE graph_9_c1.\"label\"=?\n",
      "  PARAS: ['p31_p279star', 'p31_p279star']\n",
      "---------------------------------------------\n",
      "[2021-02-11 14:09:07 sqlstore]: CREATE INDEX on table graph_9 column label ...\n",
      "[2021-02-11 14:10:30 sqlstore]: ANALYZE INDEX on table graph_9 column label ...\n",
      "node1\tlabel\tnode2\n",
      "Q1000737\tp31_p279star\tQ15075508\n",
      "Q1017471\tp31_p279star\tQ15075508\n",
      "Q10350781\tp31_p279star\tQ15075508\n",
      "Q10355535\tp31_p279star\tQ15075508\n",
      "Q10655045\tp31_p279star\tQ15075508\n",
      "Q10774749\tp31_p279star\tQ15075508\n",
      "Q1092501\tp31_p279star\tQ15075508\n",
      "Q10999547\tp31_p279star\tQ15075508\n",
      "Q1104762\tp31_p279star\tQ15075508\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {temp}/items.remove.tsv.gz -o {temp}/items.remove2.tsv.gz \\\n",
    "--match '(item)-[:p31_p279star]->(c)' \\\n",
    "--return 'distinct item, \"p31_p279star\" as label, c as node2'\n",
    "!zcat {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the items we will remove\n",
    "Check the `items.remove` file for classes added via different methods: 1) by-class, 2) by-instance, 3) by-outdegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check for class added manually, i.e. (videotape recording, 'Q34508')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videotape recording\n",
      "Q11931979\tp31_p279star\tQ34508\n",
      "Q100431477\tp31_p279star\tQ34508\n",
      "Q100982847\tp31_p279star\tQ34508\n",
      "Q100982908\tp31_p279star\tQ34508\n",
      "Q101077837\tp31_p279star\tQ34508\n",
      "Q101079766\tp31_p279star\tQ34508\n",
      "Q101094418\tp31_p279star\tQ34508\n",
      "Q101243034\tp31_p279star\tQ34508\n",
      "Q101246930\tp31_p279star\tQ34508\n",
      "Q101246967\tp31_p279star\tQ34508\n",
      "grep: write error\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!echo 'videotape recording'\n",
    "!zgrep 'Q34508' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Check for class added by-instance, i.e. (Fireball, 'Q5451712'), (whisky, 'Q281')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireball\n",
      "Q5451712\tp31_p279star\tQ281\n",
      "whisky\n",
      "Q1350656\tp31_p279star\tQ281\n",
      "Q20713240\tp31_p279star\tQ281\n",
      "Q2535077\tp31_p279star\tQ281\n",
      "Q536976\tp31_p279star\tQ281\n",
      "Q7991845\tp31_p279star\tQ281\n",
      "Q628737\tp31_p279star\tQ281\n",
      "Q5533715\tp31_p279star\tQ281\n",
      "Q16259546\tp31_p279star\tQ281\n",
      "Q96278979\tp31_p279star\tQ281\n",
      "Q982891\tp31_p279star\tQ281\n",
      "grep: write error\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!echo 'fireball'\n",
    "!zgrep 'Q5451712' {temp}/items.remove2.tsv.gz | head\n",
    "\n",
    "!echo 'whisky'\n",
    "!zgrep 'Q281' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Check for class added by-outdegree, i.e. (??, 'Q100000030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q100000030\tp31_p279star\tQ1357761\r\n",
      "Q100000030\tp31_p279star\tQ14745\r\n",
      "Q100000030\tp31_p279star\tQ14748\r\n",
      "Q100000030\tp31_p279star\tQ15401930\r\n",
      "Q100000030\tp31_p279star\tQ15621286\r\n",
      "Q100000030\tp31_p279star\tQ16686448\r\n",
      "Q100000030\tp31_p279star\tQ17537576\r\n",
      "Q100000030\tp31_p279star\tQ223557\r\n",
      "Q100000030\tp31_p279star\tQ2424752\r\n",
      "Q100000030\tp31_p279star\tQ28877\r\n"
     ]
    }
   ],
   "source": [
    "!zgrep 'Q100000030' {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the classes of items we will remove, just as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 14:12:21 sqlstore]: DROP graph data table graph_10 from /nas/home/mbmann/subset/temp.output/items.remove2.tsv.gz\n",
      "[2021-02-11 14:12:24 sqlstore]: IMPORT graph directly into table graph_10 from /nas/home/mbmann/subset/temp.output/items.remove2.tsv.gz ...\n",
      "[2021-02-11 14:12:37 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT count(DISTINCT graph_10_c1.\"node2\")\n",
      "     FROM graph_10 AS graph_10_c1\n",
      "  PARAS: []\n",
      "---------------------------------------------\n",
      "count(DISTINCT graph_10_c1.\"node2\")\n",
      "61556\n",
      "[2021-02-11 14:14:09 query]: SQL Translation:\n",
      "---------------------------------------------\n",
      "  SELECT DISTINCT graph_10_c1.\"node2\"\n",
      "     FROM graph_10 AS graph_10_c1\n",
      "     LIMIT ?\n",
      "  PARAS: [10]\n",
      "---------------------------------------------\n",
      "node2\n",
      "Q15075508\n",
      "Q208385\n",
      "Q281\n",
      "Q34508\n",
      "Q44\n",
      "Q1357761\n",
      "Q14745\n",
      "Q14748\n",
      "Q15401930\n",
      "Q15621286\n"
     ]
    }
   ],
   "source": [
    "!{kypher} -i {temp}/items.remove2.tsv.gz \\\n",
    "--match '()-[]->(n2)' \\\n",
    "--return 'count(distinct n2)' \\\n",
    "\n",
    "!{kypher} -i {temp}/items.remove2.tsv.gz \\\n",
    "--match '()-[]->(n2)' \\\n",
    "--return 'distinct n2' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TODO] Create a list of all items to protect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced edges file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the items from the all.tsv and the label, alias and description files\n",
    "We will be left with `reduced` files where the edges do not have the unwanted items. We have to remove them from the node1 and node2 positions, so we need to run the ifnotexists commands twice.\n",
    "\n",
    "Before we start preview the files to see the column headings and check whether they look sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m24.116s\r\n",
      "user\t0m24.019s\r\n",
      "sys\t0m1.801s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/items.remove2.tsv.gz -o {temp}/items.remove2.sorted.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\r\n",
      "Q100000003\tp31_p279star\tQ34508\r\n",
      "Q100000011\tp31_p279star\tQ34508\r\n",
      "Q100000014\tp31_p279star\tQ34508\r\n",
      "Q100000021\tp31_p279star\tQ34508\r\n",
      "Q100000029\tp31_p279star\tQ34508\r\n",
      "Q100000030\tp31_p279star\tQ1357761\r\n",
      "Q100000030\tp31_p279star\tQ14745\r\n",
      "\r\n",
      "gzip: Q100000030\tp31_p279star\tQ14748\r\n",
      "Q100000030\tp31_p279star\tQ15401930\r\n",
      "stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat < {temp}/items.remove2.sorted.tsv.gz | head | col\n",
    "# !zgrep 'Q34508' {temp}/items.remove.sorted.tsv.gz -c #466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove from the full set of edges those edges that have a `node1` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1\tlabel\tnode2\r\n",
      "Q1000737\tp31_p279star\tQ15075508\r\n",
      "Q1017471\tp31_p279star\tQ15075508\r\n",
      "Q10350781\tp31_p279star\tQ15075508\r\n",
      "Q10355535\tp31_p279star\tQ15075508\r\n",
      "Q10655045\tp31_p279star\tQ15075508\r\n",
      "Q10774749\tp31_p279star\tQ15075508\r\n",
      "Q1092501\tp31_p279star\tQ15075508\r\n",
      "Q10999547\tp31_p279star\tQ15075508\r\n",
      "Q1104762\tp31_p279star\tQ15075508\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat {temp}/items.remove2.tsv.gz | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t5m48.354s\r\n",
      "user\t5m46.803s\r\n",
      "sys\t0m0.782s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} ifnotexists -i {claims} -o {temp}/item.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the remaining edges, remove those that have a `node2` present in `items.remove.sorted.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t2m16.269s\r\n",
      "user\t2m21.052s\r\n",
      "sys\t0m9.241s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/item.edges.reduced.tsv.gz -o {temp}/item.edges.reduced.sorted.tsv.gz \\\n",
    "--columns node2 label node1 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t5m40.941s\r\n",
      "user\t5m39.642s\r\n",
      "sys\t0m0.499s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} ifnotexists -i {temp}/item.edges.reduced.sorted.tsv.gz -o {temp}/item.edges.reduced.2.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node2 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m27.645s\r\n",
      "user\t1m23.328s\r\n",
      "sys\t0m0.213s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} ifnotexists -i {labels} -o {temp}/label.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m11.891s\r\n",
      "user\t0m11.125s\r\n",
      "sys\t0m0.956s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/label.edges.reduced.tsv.gz -o {out}/labels.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m55.210s\r\n",
      "user\t0m52.657s\r\n",
      "sys\t0m0.143s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} ifnotexists -i {aliases} -o {temp}/alias.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a file with the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m8.524s\r\n",
      "user\t1m5.242s\r\n",
      "sys\t0m0.205s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} ifnotexists -i {descriptions} -o {temp}/description.edges.reduced.tsv.gz \\\n",
    "--filter-on {temp}/items.remove2.sorted.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys node1 \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce the output files for claims, labels, aliases and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m49.634s\r\n",
      "user\t1m48.977s\r\n",
      "sys\t0m8.109s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/item.edges.reduced.2.tsv.gz -o {out}/claims.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m11.444s\r\n",
      "user\t0m10.630s\r\n",
      "sys\t0m0.884s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/label.edges.reduced.tsv.gz -o {out}/labels.en.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m4.116s\r\n",
      "user\t0m3.818s\r\n",
      "sys\t0m0.354s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/alias.edges.reduced.tsv.gz -o {out}/aliases.en.tsv.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t0m6.953s\r\n",
      "user\t0m6.494s\r\n",
      "sys\t0m0.746s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} sort2 -i {temp}/description.edges.reduced.tsv.gz -o {out}/descriptions.en.tsv.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests: Confirm items were removed from claims file\n",
    "**NOTE:** We will check the items we removed do not exist in claims file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Confirm no instance of class added manually, i.e. (class: 'Q34508')<-(instance: 'Q100431477')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep 'Q100431477' {out}/claims.tsv.gz #PASS: No result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Confirm no target_instance of class added by source_instance, i.e. (source_instance, 'Q5451712')->(class:'Q281')<-(target_instance: Q1350656)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep 'Q1350656\t' {out}/claims.tsv.gz #PASS: No result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Confirm no instance with out-degree < 2, i.e. (instance: 'Q100000030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zgrep 'Q100000030\t' {out}/claims.tsv.gz #PASS: No result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the reduced qualifiers file\n",
    "We do this by finding all the ids of the reduced edges file, and then selecting out from `qual.tsv`\n",
    "\n",
    "We need to join by id, so we need to sort both files by id, node1, label, node2:\n",
    "\n",
    "- `{quals}` \n",
    "- `{out}/claims.tsv.gz` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                               node1                             label  node2                          node2;wikidatatype\r\n",
      "P10-P1855-Q7378-555592a4-0-P10-8a982d-0          P10-P1855-Q7378-555592a4-0        P10    \"Elephants Dream (2006).webm\"  commonsMedia\r\n",
      "P1000-P1896-f63a36-b84f3cd2-0-P1476-bf511b-0     P1000-P1896-f63a36-b84f3cd2-0     P1476  'FAI records'@en               monolingualtext\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q11736-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q11736                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q17269-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q17269                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q21208-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q21208                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q34800-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q34800                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q41079-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q41079                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q42392-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q42392                         wikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q43684-0  P1001-P1855-Q29868931-76b67d84-0  P1001  Q43684                         wikibase-item\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat < {quals} | head | column -t -s $'\\t' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `ifexists` to select out the quals for the edges in `{out}/wikidataos.qual.tsv.gz`. Note that we use `node1` in the qualifier file, matching to `id` in the `wikidataos.all.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t2m11.159s\r\n",
      "user\t2m6.879s\r\n",
      "sys\t0m0.410s\r\n"
     ]
    }
   ],
   "source": [
    "!$kgtk ifexists -i {quals} -o {out}/qualifiers.tsv.gz \\\n",
    "--filter-on {out}/claims.tsv.gz \\\n",
    "--input-keys node1 \\\n",
    "--filter-keys id \\\n",
    "--presorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the final output for qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tnode1\tlabel\tnode2\tnode2;wikidatatype\r\n",
      "P10-P1855-Q7378-555592a4-0-P10-8a982d-0 P10-P1855-Q7378-555592a4-0\tP10\t\"Elephants Dream (2006).webm\"\tcommonsMedia\r\n",
      "P1000-P1896-f63a36-b84f3cd2-0-P1476-bf511b-0\tP1000-P1896-f63a36-b84f3cd2-0\tP1476\t'FAI records'@en\tmonolingualtext\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q11736-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ11736\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q17269-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ17269\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q21208-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ21208\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q34800-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ34800\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q41079-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ41079\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q42392-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ42392\twikibase-item\r\n",
      "P1001-P1855-Q29868931-76b67d84-0-P1001-Q43684-0 P1001-P1855-Q29868931-76b67d84-0\tP1001\tQ43684\twikibase-item\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat < {out}/qualifiers.tsv.gz | head | col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call partition and useful_files notebooks, to generate the file output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgtk_scripts_path = \"/nas/home/mbmann/kgtk_subset/kgtk\"\n",
    "os.environ[\"EXAMPLES_DIR\"] = kgtk_scripts_path + \"/examples\"\n",
    "os.environ[\"USECASE_DIR\"] = kgtk_scripts_path + \"/use-cases\"\n",
    "os.environ[\"TEMP\"] = temp\n",
    "os.environ[\"OUT\"] = out\n",
    "os.environ[\"DATATYPES\"] = datatypes\n",
    "os.environ[\"METADATA\"] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nas/home/mbmann/kgtk_subset/kgtk/examples'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"EXAMPLES_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias.edges.reduced.tsv.gz\t  items.remove2.sorted.tsv.gz\r\n",
      "classes.remove2.tsv.gz\t\t  items.remove2.tsv.gz\r\n",
      "classes.remove.manual.tsv.gz\t  items.remove.byclass.tsv.gz\r\n",
      "classes.remove.p279.tsv.gz\t  items.remove.bydegree.tsv.gz\r\n",
      "classes.remove.p31.tsv.gz\t  items.remove.tsv.gz\r\n",
      "classes.remove.tsv.gz\t\t  items.small.outdegree.tsv.gz\r\n",
      "description.edges.reduced.tsv.gz  label.edges.reduced.tsv.gz\r\n",
      "item.edges.reduced.2.tsv.gz\t  metadata.out_degree.tsv.gz\r\n",
      "item.edges.reduced.sorted.tsv.gz  subclasses.remove.tsg.gz\r\n",
      "item.edges.reduced.tsv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"$TEMP\"\n",
    "# !ls {temp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aliases.en.tsv.gz\tlabels.en.tsv.gz   wikidata.sqlite3.db\r\n",
      "claims.tsv.gz\t\tlabels.tsv.gz\r\n",
      "descriptions.en.tsv.gz\tqualifiers.tsv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"$OUT\"\n",
    "# !ls {out}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate all output files together** <br>\n",
    "\n",
    "**NOTE:** The `metadata.property.datatypes` and `metadata.types` are not currently generated by this notebook, and have been copied from `wikidata-20200803-v5/data`. <br>\n",
    "**TODO:** We must confirm if these are source files, or computed. If they are computed, we should compute them in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t19m58.174s\r\n",
      "user\t19m54.510s\r\n",
      "sys\t0m0.911s\r\n"
     ]
    }
   ],
   "source": [
    "!{kgtk} cat \\\n",
    "-i {out}/aliases.en.tsv.gz \\\n",
    "-i {out}/descriptions.en.tsv.gz \\\n",
    "-i {out}/qualifiers.tsv.gz \\\n",
    "-i {out}/claims.tsv.gz \\\n",
    "-i {out}/labels.en.tsv.gz \\\n",
    "-i {datatypes} \\\n",
    "-i {metadata} \\\n",
    "-o {out}/all.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nas/home/mbmann/kgtk_subset/kgtk/examples/partition-wikidata.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls {os.environ[\"EXAMPLES_DIR\"] + \"/partition-wikidata.ipynb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-64e08e0bdd18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtemp_folder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OUT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/parts/temp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msort_extras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"--buffer-size 30% --temporary-directory $OUT/parts/temp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/papermill/execute.py\u001b[0m in \u001b[0;36mexecute_notebook\u001b[0;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mstdout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mstderr_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 )\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/papermill/engines.py\u001b[0m in \u001b[0;36mexecute_notebook_with_engine\u001b[0;34m(self, engine_name, nb, kernel_name, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_notebook_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m\"\"\"Fetch a named engine and execute the nb object against it.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/papermill/engines.py\u001b[0m in \u001b[0;36mexecute_notebook\u001b[0;34m(cls, nb, kernel_name, output_path, progress_bar, log_output, autosave_cell_every, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mlog_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mautosave_cell_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautosave_cell_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         )\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/papermill/engines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nb, output_path, log_output, progress_bar, autosave_cell_every)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Executing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kgtk-subset/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             raise ImportError(\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "pm.execute_notebook(\n",
    "    os.environ[\"EXAMPLES_DIR\"] + \"/partition-wikidata.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/partition-wikidata.out.ipynb\",\n",
    "    parameters=dict(\n",
    "        wikidata_input_path = os.environ[\"OUT\"] + \"/all.tsv.gz\",\n",
    "        wikidata_parts_path = os.environ[\"OUT\"] + \"/parts\",\n",
    "        temp_folder_path = os.environ[\"OUT\"] + \"/parts/temp\",\n",
    "        sort_extras = \"--buffer-size 30% --temporary-directory $OUT/parts/temp\",\n",
    "        verbose = False\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.execute_notebook(\n",
    "    os.environ[\"USECASE_DIR\"] + \"/Wikidata Useful Files.ipynb\",\n",
    "    os.environ[\"TEMP\"] + \"/Wikidata Useful Files Out.ipynb\",\n",
    "    parameters=dict(\n",
    "        output_path = os.environ[\"OUT\"],\n",
    "        output_folder = \"useful_files\",\n",
    "        temp_folder = \"temp.useful_files\",\n",
    "        wiki_root_folder = os.environ[\"OUT\"] + \"/parts/\",\n",
    "        cache_path = os.environ[\"OUT\"] + \"/temp.useful_files\",\n",
    "        languages = 'en',\n",
    "        compute_pagerank = True,\n",
    "        delete_database = False\n",
    "    )\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "\n",
    "- After removing classes, check that the class does not occur in the resulting claims file. \n",
    "- After protecting classes, check the class was occurs in the resulting claims file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the class we removed `Q34508` was removed from claims file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz \\\n",
    "--match '(n1:Q34508)-[l]->(n2)' \\\n",
    "--limit 10 \\\n",
    "| col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz \\\n",
    "--match '(n1:P131)-[l]->(n2)' \\\n",
    "--limit 10 \\\n",
    "| col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the derived files using the `Wikidata Useful Files` Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute `claims.wikibase-item.tsv.gz` which would be computed by the Wikidata partitioner, but we are not using it here yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < \"{datatypes}\" | head | col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kypher} -i {out}/claims.tsv.gz -i \"{datatypes}\" -o {out}/claims.wikibase-item.tsv.gz \\\n",
    "--match 'claims: (n1)-[l {label: p}]->(n2), datatypes: (p)-[:datatype]->(:`wikibase-item`)' \\\n",
    "--return 'l as id, n1 as node1, p as label, n2 as node2' \\\n",
    "--order-by 'l' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the derived files we use papermill to run the `Wikidata Useful Files` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.execute_notebook(\n",
    "    notebooks_folder + useful_files_notebook,\n",
    "    temp + \"/useful_files_notebook_output.ipynb\",\n",
    "    parameters=dict(\n",
    "        output_path=output_path,\n",
    "        output_folder=output_folder,\n",
    "        temp_folder=temp_folder,\n",
    "        wiki_root_folder=wiki_root_folder,\n",
    "        claims_file=\"claims.tsv.gz\",\n",
    "        label_file=\"labels.en.tsv.gz\",\n",
    "        alias_file=\"aliases.en.tsv.gz\",\n",
    "        description_file=\"descriptions.en.tsv.gz\",\n",
    "        item_file=\"claims.wikibase-item.tsv.gz\",\n",
    "        cache_path=cache_path,\n",
    "        delete_database=delete_database,\n",
    "        compute_pagerank=compute_pagerank\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the columns so we know how to construct the kypher query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {out}/*wikidataos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zcat < {out}/wikidataos.all.tsv.gz | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges file must contain edges for properties, this is not the case on 2020-11-10`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{kgtk} -i \"{claims}\" \\\n",
    "--match '(:P10)-[l]->(n2)' \\\n",
    "--limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lad = []\n",
    "if 'en' not in languages:\n",
    "    languages.append('en')\n",
    "for lang in languages:\n",
    "    lad.append(f\"{out}/labels.{lang}.tsv.gz\")\n",
    "    lad.append(f\"{out}/aliases.{lang}.tsv.gz\")\n",
    "    lad.append(f\"{out}/descriptions.{lang}.tsv.gz\")\n",
    "lad_file_list = \" \".join(lad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat -i {out}/claims.tsv.gz \\\n",
    "{lad_file_list} \\\n",
    "{out}/qualifiers.tsv.gz \\\n",
    "{out}/metadata.pagerank.undirected.tsv.gz \\\n",
    "{out}/metadata.pagerank.directed.tsv.gz \\\n",
    "{out}/metadata.in_degree.tsv.gz \\\n",
    "{out}/metadata.out_degree.tsv.gz \\\n",
    "-o {out}/wikidataos.all.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate files to get the `all for triples` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk cat -i $OUT/wikidataos.all.tsv.gz \\\n",
    "$OUT/derived.P31.tsv.gz \\\n",
    "$OUT/derived.P279.tsv.gz \\\n",
    "$OUT/derived.isa.tsv.gz \\\n",
    "$OUT/derived.P279star.tsv.gz \\\n",
    "-o $OUT/wikidataos.all.for.triples.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out `novalue`, `somevalue` and `P9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk filter -i $OUT/wikidataos.all.for.triples.tsv.gz \\\n",
    "    -o $OUT/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "    -p ';;somevalue,novalue,P9' --invert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ids for any edge with missing id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk add-id -i $OUT/wikidataos.all.for.triples.filtered.tsv.gz \\\n",
    "-o $OUT/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "--id-style wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by `id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk sort2 -i $OUT/wikidataos.all.for.triples.filtered.id.tsv.gz \\\n",
    "-o $OUT/wikidataos.all.for.triples.filtered.id.sorted.tsv.gz \n",
    "-c id"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "kgtk-subset",
   "language": "python",
   "name": "kgtk-subset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
